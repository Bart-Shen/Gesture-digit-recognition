{
 "metadata": {
  "name": "",
  "signature": "sha256:fa7e6c6b17097e7f0c015a6d63ca784bf6b7c6536f991597a555ef8631f547d0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "import numpy as np\n",
      "import h5py\n",
      "import matplotlib.pyplot as plt\n",
      "import tensorflow as tf\n",
      "from tensorflow.python.framework import ops\n",
      "from tf_utils import load_dataset, random_mini_batches, convert_to_one_hot, predict\n",
      "\n",
      "%matplotlib inline\n",
      "np.random.seed(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Liner_fuction():\n",
      "    np.random.seed(1)\n",
      "    X = tf.constant(np.random.randn(3,1),name = 'X')\n",
      "    W = tf.constant(np.random.randn(4,3), name = 'W')\n",
      "    b = tf.constant(np.random.randn(4,1),name = 'b')\n",
      "    \n",
      "    Y = tf.add(tf.matmul(W ,X),b)\n",
      "    sess = tf.Session()\n",
      "    result = sess.run(Y)\n",
      "    \n",
      "    sess.close()\n",
      "    \n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print (\"result:\" + str(Liner_fuction()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "result:[[-2.15657382]\n",
        " [ 2.95891446]\n",
        " [-1.08926781]\n",
        " [-0.84538042]]\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sigmoid(z):\n",
      "    x = tf.placeholder(tf.float32, name='x')\n",
      "    sigmoid = tf.sigmoid(x)\n",
      "    with tf.Session() as sess:\n",
      "        result = sess.run(sigmoid,feed_dict={x:z})\n",
      "        \n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print (sigmoid(0))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.5\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cost(logits, label):\n",
      "    logits1 = tf. placeholder(tf.float32, name = 'logits')\n",
      "    label1 = tf.placeholder(tf.float32, name = 'label')\n",
      "    \n",
      "    cost = tf.nn.sigmoid_cross_entropy_with_logits(logits = logits1, labels = label1)\n",
      "    with tf.Session() as sess:\n",
      "        result = sess.run(cost, feed_dict={logits1:logits,label1:label})\n",
      "        \n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logits = sigmoid([0.2,0.4,0.6,0.8])\n",
      "label = [0 ,0, 1, 1]\n",
      "print (logits)\n",
      "print (cost(logits, label))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.54983395  0.59868765  0.64565629  0.68997449]\n",
        "[ 1.00538719  1.03664088  0.42154732  0.40652379]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def one_hot(labels, C):\n",
      "    depth = tf.constant(C)\n",
      "    one_hot = tf.one_hot(labels ,depth, axis = 0)\n",
      "    with tf.Session() as sess:\n",
      "        result = sess.run(one_hot)\n",
      "    \n",
      "    return result\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels = [1, 3, 2, 0, 3, 2]\n",
      "print (one_hot(labels, C=4))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.  0.  0.  1.  0.  0.]\n",
        " [ 1.  0.  0.  0.  0.  0.]\n",
        " [ 0.  0.  1.  0.  0.  1.]\n",
        " [ 0.  1.  0.  0.  1.  0.]]\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with tf.Session() as sess:\n",
      "    print (sess.run(tf.ones([3,2,4])))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[[ 1.  1.  1.  1.]\n",
        "  [ 1.  1.  1.  1.]]\n",
        "\n",
        " [[ 1.  1.  1.  1.]\n",
        "  [ 1.  1.  1.  1.]]\n",
        "\n",
        " [[ 1.  1.  1.  1.]\n",
        "  [ 1.  1.  1.  1.]]]\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print (X_train_orig.size)\n",
      "X_train_flatten = X_train_orig.reshape(X_train_orig.shape[0], -1).T\n",
      "print (X_train_flatten/255)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13271040\n",
        "[[ 0.89019608  0.93333333  0.89411765 ...,  0.92156863  0.91372549\n",
        "   0.90196078]\n",
        " [ 0.8627451   0.90980392  0.8627451  ...,  0.88627451  0.88627451\n",
        "   0.8627451 ]\n",
        " [ 0.83921569  0.8745098   0.81568627 ...,  0.84705882  0.85098039\n",
        "   0.81960784]\n",
        " ..., \n",
        " [ 0.81568627  0.84313725  0.82745098 ...,  0.78431373  0.8         0.79215686]\n",
        " [ 0.81960784  0.8         0.81176471 ...,  0.75294118  0.78823529\n",
        "   0.78039216]\n",
        " [ 0.81960784  0.75294118  0.79215686 ...,  0.71372549  0.77647059\n",
        "   0.77254902]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y_train = one_hot(Y_train_orig, 6)\n",
      "Y_train = Y_train.reshape(Y_train.shape[0], -1)\n",
      "print(Y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.  1.  0. ...,  0.  0.  0.]\n",
        " [ 0.  0.  0. ...,  0.  0.  0.]\n",
        " [ 0.  0.  1. ...,  1.  0.  0.]\n",
        " [ 0.  0.  0. ...,  0.  0.  0.]\n",
        " [ 0.  0.  0. ...,  0.  1.  0.]\n",
        " [ 1.  0.  0. ...,  0.  0.  1.]]\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y_train = convert_to_one_hot(Y_train_orig, 6)\n",
      "print(Y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.  1.  0. ...,  0.  0.  0.]\n",
        " [ 0.  0.  0. ...,  0.  0.  0.]\n",
        " [ 0.  0.  1. ...,  1.  0.  0.]\n",
        " [ 0.  0.  0. ...,  0.  0.  0.]\n",
        " [ 0.  0.  0. ...,  0.  1.  0.]\n",
        " [ 1.  0.  0. ...,  0.  0.  1.]]\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train_flaten = X_train_orig.reshape(X_train_orig.shape[0], -1).T\n",
      "print (X_train_flaten.shape)\n",
      "X_test_flaten = X_test_orig.reshape(X_test_orig.shape[0], -1).T\n",
      "\n",
      "X_train_flaten = X_train_flaten/255\n",
      "X_test_flaten = X_test_flaten/255\n",
      "\n",
      "Y_test = convert_to_one_hot(Y_test_orig, 6)\n",
      "Y_train = convert_to_one_hot(Y_train_orig, 6)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(12288, 1080)\n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def creat_placeholder(n_x, n_y):\n",
      "    X = tf.placeholder(tf.float32, shape=(n_x,None) ,name='X')\n",
      "    Y = tf.placeholder(tf.float32, shape=(n_y,None) ,name='Y')\n",
      "    return X ,Y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, Y = creat_placeholder(12288, 6)\n",
      "print (X)\n",
      "print (Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Tensor(\"X_2:0\", shape=(12288, ?), dtype=float32)\n",
        "Tensor(\"Y_1:0\", shape=(6, ?), dtype=float32)\n"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def initializer_parameters():\n",
      "    tf.set_random_seed(1)\n",
      "    W1 = tf.get_variable('W1', [25,12288], initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
      "    b1 = tf.get_variable('b1', [25,1], initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
      "    W2 = tf.get_variable('W2', [12,25], initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
      "    b2 = tf.get_variable('b2', [12,1], initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
      "    W3 = tf.get_variable('W3', [6,12], initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
      "    b3 = tf.get_variable('b3', [6,1], initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
      "    parameters = {'W1':W1, 'W2':W2, 'W3':W3, 'b1':b1, 'b2':b2, 'b3':b3}\n",
      "\n",
      "    return parameters\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "parameters = initializer_parameters()\n",
      "print (parameters['W1'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "Variable W1 already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"<ipython-input-64-690e4f4209e3>\", line 3, in initializer_parameters\n    W1 = tf.get_variable('W1', [25,12288], initializer = tf.contrib.layers.xavier_initializer(seed=1))\n  File \"<ipython-input-74-d4eeeb9e7159>\", line 5, in <module>\n    parameters = initializer_parameters()\n  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2883, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-76-7288a9fb74ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializer_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-75-07162e20b66a>\u001b[0m in \u001b[0;36minitializer_parameters\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minitializer_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_random_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mW1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12288\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxavier_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxavier_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mW2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'W2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxavier_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1201\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m       constraint=constraint)\n\u001b[0m\u001b[1;32m   1204\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m   1205\u001b[0m     \"\"\"%s\n",
        "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1090\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m           \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m   1093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m   def _get_partitioned_variable(self,\n",
        "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m    423\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m           \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   def _get_partitioned_variable(\n",
        "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    392\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m           use_resource=use_resource, constraint=constraint)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    740\u001b[0m                          \u001b[0;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 742\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    743\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: Variable W1 already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"<ipython-input-64-690e4f4209e3>\", line 3, in initializer_parameters\n    W1 = tf.get_variable('W1', [25,12288], initializer = tf.contrib.layers.xavier_initializer(seed=1))\n  File \"<ipython-input-74-d4eeeb9e7159>\", line 5, in <module>\n    parameters = initializer_parameters()\n  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2883, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def forward_propagation(x, parameters):\n",
      "    W1 = parameters['W1']\n",
      "    W2 = parameters['W2']\n",
      "    W3 = parameters['W3']\n",
      "    b1 = parameters['b1']\n",
      "    b2 = parameters['b2']\n",
      "    b3 = parameters['b3']\n",
      "    \n",
      "    out = tf.matmul(W1,x) + b1\n",
      "    out = tf.nn.relu(out)\n",
      "    out = tf.matmul(W2,out) +  b2\n",
      "    out = tf.nn.relu(out)\n",
      "    out = tf.matmul(W3,out) + b3\n",
      "    \n",
      "    return out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tf.reset_default_graph()\n",
      "\n",
      "with tf.Session() as sess:\n",
      "    X, Y = creat_placeholder(12288, 6)\n",
      "    parameters = initializer_parameters()\n",
      "    out = forward_propagation(X, parameters)\n",
      "\n",
      "print (out)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Tensor(\"add_2:0\", shape=(6, ?), dtype=float32)\n"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compute_cost(out, y):\n",
      "    logits = tf.transpose(out)\n",
      "    labels = tf.transpose(y)\n",
      "    \n",
      "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels=labels))\n",
      "    return cost"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tf.reset_default_graph()\n",
      "with tf.Session() as sess:\n",
      "    X, Y = creat_placeholder(12288, 6)\n",
      "    parameters = initializer_parameters()\n",
      "    out = forward_propagation(X, parameters)\n",
      "    cost = compute_cost(out, Y)\n",
      "print (cost)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
      "          nums_epoch = 1500, minibatch_size = 32, print_cost = True):\n",
      "    tf.reset_default_graph()\n",
      "    tf.set_random_seed(1)\n",
      "    seed = 3\n",
      "    (n_x, m)= X_train.shape\n",
      "    n_y = Y_train.shape[0]\n",
      "    cost = []\n",
      "    \n",
      "    X, Y = creat_placeholder(n_x, n_y)\n",
      "    parameters = initializer_parameters()\n",
      "    out = forward_propagation(X, parameters)\n",
      "    cost = compute_cost(out, Y)\n",
      "    optimizer = tf.train.AdamOptimizer(learning_rate).minisize(cost)\n",
      "    \n",
      "    init = tf.global_variables_initializer()\n",
      "    \n",
      "    with tf.Session() as sess:\n",
      "        sess.run(init)\n",
      "        for epoch in range(nums_epoch):\n",
      "            epoch_cost = 0\n",
      "            num_minibatches = int(m / minibatch_size)\n",
      "            seed = seed+1\n",
      "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
      "            \n",
      "            for minibatch in minibatches:\n",
      "                (minibatch_X, minibatch_Y) = minibatch\n",
      "                _, minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y:minibatch_Y})\n",
      "                epoch_cost += minibatch_cost / num_minibatches\n",
      "            \n",
      "            if print_cost == True and epoch % 100 ==0:\n",
      "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
      "            if print_cost == True and epoch%5 == 0:\n",
      "                costs.append(epoch_cost)\n",
      "        \n",
      "        plt.plot(np.squeeze(costs))\n",
      "        plt.ylabel('cost')\n",
      "        plt.xlabel('iterations (per tens)')\n",
      "        plt.title(\"Learning rate = \" + str(learning_rate))\n",
      "        plt.show()\n",
      "        \n",
      "        parameters = sess.run(parameters)\n",
      "        print(\"Parameters have benn trained!\")\n",
      "        correct_prediction = tf.equal(tf.argmax(out), tf.argmax(Y))\n",
      "        \n",
      "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
      "        \n",
      "        print(\"Train Accuracy:\", accuracy.eval({X:X_train, Y:Y_train}))\n",
      "        print (\"Test Accuracy:\", accuracy.eval({X:X_test, Y:Y_test}))\n",
      "        \n",
      "        return parameters"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}